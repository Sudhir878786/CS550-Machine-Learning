{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "$$Name  \\hspace{0.6cm} Sudhir \\hspace{0.3cm} Sharma$$\n",
        "$$ID  \\hspace{0.6cm} 12041500$$\n",
        "$$Branch  \\hspace{0.6cm} CSE $$\n",
        "$$HomeWork  \\hspace{0.5cm} II \\hspace{0.3cm} CS550$$\n"
      ],
      "metadata": {
        "id": "xL8pJdBh0Np7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 1\n",
        "\n",
        "**Deriving Decision Boundary for Learning with Prototypes LwP Classifier**\n",
        "\n",
        "Given training examples of +ve class\n",
        "\n",
        "    (2,3,4); (1,1,2); (0,2,0)\n",
        "\n",
        "\n",
        "Given training examples of -ve class\n",
        "\n",
        "      (4,3,2); (2,1,1); (3,5,3)"
      ],
      "metadata": {
        "id": "utOww61-7RiK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer**\n",
        "\n",
        "**To Compute the average feature vectors of +ve and -ve class examples. \n",
        "Let us call them 𝝁+ i used**\n",
        "\n",
        "\n",
        "1 . \n",
        "\n",
        "$$\n",
        " 𝝁+=\\frac{1}{N_+}\\Sigma(x_i)\n",
        "$$\n",
        "\n",
        "$$ \n",
        " 𝝁+=(\\frac{(2+1+0),(3+1+2),(4+2+0))}{3})\n",
        "$$\n",
        "\n",
        "$$\n",
        " 𝝁+=(1,2,2)\n",
        "$$\n",
        "\n",
        "    \n",
        "\n"
      ],
      "metadata": {
        "id": "JthQou1X7u3f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ii.) \n",
        "\n",
        "**Answer**\n",
        "\n",
        "**To Compute the average feature vectors of +ve and -ve class examples. \n",
        "Let us call them 𝝁− i used**\n",
        "\n",
        "$$\n",
        " 𝝁-=\\frac{1}{N_-}\\Sigma(x_i)\n",
        "$$\n",
        "\n",
        "\n",
        "$$ \n",
        " 𝝁-=(\\frac{(4+2+3),(3+1+5),(2+1+3)}{3})\n",
        "$$\n",
        "$$\n",
        " 𝝁-= (3,3,2)\n",
        "$$\n",
        "\n",
        "     \n"
      ],
      "metadata": {
        "id": "My91-RfgDN-y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Determine the vector 𝒘 which joins 𝜇+ and 𝜇− : 𝒘 = 𝝁+ − 𝝁−\n",
        "\n",
        "\n",
        "    𝝁+ − 𝝁−=(1,2,2)-(3,3,2)\n",
        "    𝒘 = (-2,-1,0)\n",
        "\n"
      ],
      "metadata": {
        "id": "YGQZfl07DjLz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Given decision boundary passes through the mid-point of the prototypes.\n",
        "\n",
        "Given\n",
        "$$\n",
        "  midpoint=\\frac{1}{2}(\\mu_++\\mu_-)\n",
        "$$\n",
        "\n",
        "\n",
        "$$\n",
        "  equation=> w^T+b=0\n",
        "$$\n",
        "\n",
        "$$\n",
        "    midpoint=(\\frac{(1+3),(2+3),(2+2))}{2})\n",
        "$$\n",
        "\n",
        "$$\n",
        "    midpoint=(2,2.5,2)\n",
        "$$\n",
        "\n",
        "\n",
        "$$\n",
        "b=-w^Tx   \n",
        "$$\n",
        "\n",
        "\n",
        "$$\n",
        "  b=-\\begin{bmatrix} \n",
        "\t-2 & -1 & 0 \\\\\n",
        "\t\\end{bmatrix}\n",
        "  \\begin{bmatrix} \n",
        "\t2 \\\\\n",
        "  2.5 \\\\ \n",
        "  2 \\\\\n",
        "\t\\end{bmatrix}\n",
        "$$\n",
        "The value of b come out to be\n",
        "$$\n",
        "  b=6.5\n",
        "$$\n",
        "\n",
        "Equation of the Decision boundary is (-2,-1,0)x +6.5=0\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-0nFyMAWD5H_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Compute the distances of the training examples from the decision boundary. Are there \n",
        "any errors in classification using the LwP classifier?\n",
        "\n",
        "    Distances calculated below part 1 question 5\n",
        "\n",
        "Boundary Equations came out is \n",
        "\n",
        "Equation of the Decision boundary is$$(-2,-1,0)x +6.5=0$$\n",
        "\n",
        "Let $$x=(x,y,z)$$  then boundary equation became $$-2x-y+6.5=0$$\n",
        "\n",
        "Distance of training examples from decision boundary $$d=(\\frac{-2x-y+6.5}{\\sqrt{5}})$$\n",
        "**positive class**\n",
        "\n",
        "$$\n",
        "(2,3,4) => \\begin{bmatrix} \n",
        "\t-2 & -1 & 0 \\\\\n",
        "\t\\end{bmatrix}\n",
        "  \\begin{bmatrix} \n",
        "\t2 \\\\\n",
        "  3 \\\\ \n",
        "  4 \\\\\n",
        "\t\\end{bmatrix} + 6.5 = -7+6.5=-0.5=>d1\n",
        "$$\n",
        "$$\n",
        "(1,1,2) => \\begin{bmatrix} \n",
        "\t-2 & -1 & 0 \\\\\n",
        "\t\\end{bmatrix}\n",
        "  \\begin{bmatrix} \n",
        "\t1 \\\\\n",
        "  1 \\\\ \n",
        "  2 \\\\\n",
        "\t\\end{bmatrix} + 6.5 = -3+6.5=2.5=>d2\n",
        "$$\n",
        "$$\n",
        "(0,2,0) => \\begin{bmatrix} \n",
        "\t-2 & -1 & 0 \\\\\n",
        "\t\\end{bmatrix}\n",
        "  \\begin{bmatrix} \n",
        "\t0 \\\\\n",
        "  2 \\\\ \n",
        "  0 \\\\\n",
        "\t\\end{bmatrix} + 6.5 = -2+6.5=4.5=>d3\n",
        "$$\n",
        "\n",
        "**negative class**\n",
        "\n",
        "$$\n",
        "(4,3,2) => \\begin{bmatrix} \n",
        "\t-2 & -1 & 0 \\\\\n",
        "\t\\end{bmatrix}\n",
        "  \\begin{bmatrix} \n",
        "\t4 \\\\\n",
        "  3 \\\\ \n",
        "  2 \\\\\n",
        "\t\\end{bmatrix} + 6.5 = -11+6.5=-4.5=>d4\n",
        "$$\n",
        "$$\n",
        "(2,1,1) => \\begin{bmatrix} \n",
        "\t-2 & -1 & 0 \\\\\n",
        "\t\\end{bmatrix}\n",
        "  \\begin{bmatrix} \n",
        "\t1 \\\\\n",
        "  1 \\\\ \n",
        "  2 \\\\\n",
        "\t\\end{bmatrix} + 6.5 = -5+6.5=1.5=>d5\n",
        "$$\n",
        "$$\n",
        "(3,5,3) => \\begin{bmatrix} \n",
        "\t-2 & -1 & 0 \\\\\n",
        "\t\\end{bmatrix}\n",
        "  \\begin{bmatrix} \n",
        "\t3 \\\\\n",
        "  5 \\\\ \n",
        "  3 \\\\\n",
        "\t\\end{bmatrix} + 6.5 = -11+6.5=-4.5=>d6\n",
        "$$\n",
        "\n",
        "\n",
        "**Yes there are errors in classification using LwP , we can see that d1 for +ve class give -ve distance and d5 for -ve class give +ve distance. But According to LwP classifier +ve class should have +ve distance and -ve class should have -ve distance. In sort some pos points are classified as neg while some neg points are classified as pos.** \n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zjBrsW2OD-ku"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Find the equation of a linear classifier which separates the data without any error? If no \n",
        "such classifier exists, give a justification."
      ],
      "metadata": {
        "id": "7wSAfMZ3EG4P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "pos=[[2,3,4],[1,1,2],[0,2,0]]\n",
        "neg=[[4,3,2],[2,1,1],[3,5,3]]\n",
        "predicted_w=np.matrix([-2,-1,0])\n",
        "predicted_b=6.5"
      ],
      "metadata": {
        "id": "e7OKpgkGZCjw"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "while (True):\n",
        "  y=0 # flag to check if there is error\n",
        "  c=0 # count to check at final if the error persists\n",
        "  # for pos\n",
        "  for i in range(3):\n",
        "    np_mat=np.matrix(pos[i]).T\n",
        "    mat=np.dot(predicted_w,np_mat)\n",
        "    to_list=mat.tolist()\n",
        "    num=to_list[0][0]+predicted_b\n",
        "    # print(num,\"pos\")\n",
        "    if (num<0):\n",
        "      predicted_w=predicted_w+pos[i]\n",
        "      predicted_b+=1\n",
        "      # print(predicted_w,predicted_b,\"pos\")\n",
        "      c+=1\n",
        "  # for neg\n",
        "  for i in range(3):\n",
        "    np_mat=np.matrix(neg[i]).T\n",
        "    mat=np.dot(predicted_w,np_mat)\n",
        "    to_list=mat.tolist()\n",
        "    num=to_list[0][0]+predicted_b\n",
        " \n",
        "    if (num>0):\n",
        "      predicted_w=predicted_w-neg[i]\n",
        "      predicted_b-=1\n",
        "   \n",
        "      c+=1\n",
        "\n",
        "  if (c==0):\n",
        "    break\n",
        "\n",
        "print(f'Finalscore for w is {predicted_w} ')\n",
        "print (f'and final bias is {predicted_b}')\n",
        "  \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "232Z03fLewFt",
        "outputId": "6f6fe907-8133-4777-b42b-5bbd7062c9e8"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finalscore for w is [[-4 -1  2]] \n",
            "and final bias is 6.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# Part 1  4th question compute the distances\n",
        "pos=[[2,3,4],[1,1,2],[0,2,0]]\n",
        "neg=[[4,3,2],[2,1,1],[3,5,3]]\n",
        "w=[-2,-1,0]"
      ],
      "metadata": {
        "id": "6CAM6uF-ayWO"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Distance from pos points\n",
        "for i in range(3):\n",
        "  ans=np.dot(w,pos[i])/np.linalg.norm(w)\n",
        "  print(f'Distance of +ve class {str(pos[i])} from boundry is {ans}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "qIyMy9tfa3F3",
        "outputId": "89a4a81a-43db-4800-bc33-adc826a2270b"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distance of +ve class [2, 3, 4] from boundry is -3.1304951684997055\n",
            "Distance of +ve class [1, 1, 2] from boundry is -1.3416407864998738\n",
            "Distance of +ve class [0, 2, 0] from boundry is -0.8944271909999159\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Distance from neg points\n",
        "for i in range(3):\n",
        "  ans=np.dot(w,neg[i])/np.linalg.norm(w)\n",
        "  print(f'Distance of -ve class {str(neg[i])} from boundry is {ans}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "KlDLVWytMAlu",
        "outputId": "e774813b-9d8f-41b3-a669-f4dcff9824a0"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distance of -ve class [4, 3, 2] from boundry is -4.919349550499537\n",
            "Distance of -ve class [2, 1, 1] from boundry is -2.23606797749979\n",
            "Distance of -ve class [3, 5, 3] from boundry is -4.919349550499537\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "4qZhwQw4INsG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 2\n",
        "\n",
        "**i.) Explain the importance of scaling features for training Large Margin Classifiers?**\n",
        "\n",
        "\n",
        "Scaling is the process of normalizing data, which sets the mean of data to 0 and the standard deviation as 1.\n",
        "\n",
        "It makes the model easy to learn because if there exists a variable with a large spread it may cause a large loss in training.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4DL8l2D-IXfe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ii.)Explain the effect of changing the value of C from very small to very large in a Soft margin ?**\n",
        "\n",
        "\n",
        "For large values of C, the optimization will choose a smaller-margin hyperplane if that hyperplane does a better job of getting all the training points classified correctly. Conversely, a very small value of C will cause the optimizer to look for a larger-margin separating hyperplane, even if that hyperplane misclassifies more points. For very tiny values of C, we should get misclassified examples, often even if our training data is linearly separable.\n",
        "\n",
        "Here in $$CΣ^{N}_{i=1}{z_i}$$, $z_i$ is the slack, and C mutiplied with it increases the influence of the equation. Therefore, for high levels of C, the model prioritises minimising those slacks over lowering w.\n",
        "For small values of C, $Σ^{N}_{i=1}z_i$ is also small, and has less significance in the objective function, and so, allows more violations of margin.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FAAewr16dlNy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**iii.)Consider the 2-D array, arr. What is the output of np.sum(arr, axis=1)?**\n",
        "\n",
        "$$\n",
        "  Let \\hspace{0.5cm}arr=[[0,1,13],[31,43,25]]\n",
        "  \\\\after \\hspace{0.5cm}applying \\hspace{0.5cm}np.sum(arr, axis=1) => [14, 99]\\\\\n",
        "$$\n",
        "\n"
      ],
      "metadata": {
        "id": "gghc5Zthdqm1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "blATCgR9eK0y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " import numpy as np\n",
        " arr=[[0,1,13],[31,43,25]]\n",
        " np.sum(arr, axis=1)       # so it gives sum horizontally across the columns."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "upnvzsEoeOPa",
        "outputId": "0239db52-2ccc-46d3-8c42-95f036eb9a48"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([14, 99])"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**iv.) Which of the following are methods for indexing into a DataFrame?**\n",
        "\n",
        "    d.) All of the above\n",
        "\n",
        "    data.iloc[[0, 2, 4, 7]]\n",
        "    data.loc[2:5]\n",
        "    data.set_index('column_name')\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NpUKLxf_dvWv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**v.) What is an indicator feature**\n",
        "\n",
        "   b.)A feature that represents categorical data, using 1’s and 0’s to denote which categories are present.\n",
        "\n",
        "   An indicator feature is a function which maps to 1 if the datapoint belongs to certain subset or else it maps rest of the points to 0.\n",
        "\n",
        "The expectation of the indicator function is equal to the probability of the event.\n",
        "\n",
        "The indicator function is typically used to define the loss function used in classification. The property related to its expectation then implies that the classification risk is the probability of misclassification.\n",
        "\n",
        "In pictures..."
      ],
      "metadata": {
        "id": "EPSsH9Lyd0KQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**vi.) What is the main purpose of standardizing data?**\n",
        "\n",
        "    a.) It lets us view data in terms of standard deviations from the average case (i.e. mean)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fU2-kpcAd7Fw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**vii.) For the given confusion matrix, please calculate accuracy, precision, recall and F1 score**\n",
        "\n",
        "![a.png](data:image/png;base64,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)\n",
        "\n",
        "\n",
        " \n",
        "$$\n",
        "    TP=12$$\n",
        "    $$ \n",
        "    TN=9$$\n",
        "    $$\n",
        "    FP=3$$\n",
        "    $$\n",
        "    FN=1\n",
        "$$\n",
        "\n",
        "$$\n",
        "1.)Precision=\\frac {TP}{FP+TP} \\\\ => \\frac{12}{3+12}=>0.8\n",
        "$$\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "i-5yvTvzd_Jz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RECALL"
      ],
      "metadata": {
        "id": "U08SCfIZk-dD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$\n",
        "2.)Recall=\\frac {TP}{FN+TP} \\\\ => \\frac{12}{1+12}=>0.92\n",
        "$$\n"
      ],
      "metadata": {
        "id": "wxWAngpXkz5z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### F1Score"
      ],
      "metadata": {
        "id": "qm9nbmI6lDYK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$\n",
        "3.)F_1 Score=\\frac {1}{\\frac{1}{Precision}+\\frac{1}{Recall}} \\\\ => \\frac {1}{\\frac{1}{0.8}+\\frac{1}{0.92}}=>\\frac{1}{1.25+1.08}=>0.42\n",
        "$$\n"
      ],
      "metadata": {
        "id": "n4VeBDsbk2sW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Accuracy"
      ],
      "metadata": {
        "id": "f5c5JCawlKJ1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$\n",
        "4.)Accuracy=\\frac{TP+TN}{TP+TN+FP+FN} \\\\ =>\\frac{12+9}{12+9+3+1}\\\\\n",
        "=>\\frac{21}{25} \\\\ =>0.84\n",
        "$$"
      ],
      "metadata": {
        "id": "fwRq9urqk5bp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**viii.) What is the difference between bagging and boosting? Which technique would be suitable when the data has high variance?**\n",
        "\n",
        "**Bagging**: It is a homogeneous weak learners’ model that learns from each other independently in parallel and combines them for determining the model average.\n",
        "\n",
        "**Boosting:** It is also a homogeneous weak learners’ model but works differently from Bagging. In this model, learners learn sequentially and adaptively to improve model predictions of a learning algorithm.\n",
        "\n",
        "    Bagging method is used when the data has high variance.\n",
        "\n"
      ],
      "metadata": {
        "id": "yghKRMgYeE9w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### ix.) Justify the cost function 𝐿(𝒘) used by logistic regression for binary classification and \n",
        "compute its gradient $$\\frac{𝜕𝐿}{𝜕𝑤}$$\n",
        "with respect to parameters**\n",
        "\n",
        "\n",
        "\n",
        "$$\n",
        "  L(w)=\\Sigma^{N}_{i=1}(y_i{(p)} + (1-y_i)log(1-p)) \\\\\n",
        "  \\frac{𝜕𝐿(w)}{𝜕𝑤}= \\frac{𝜕(\\Sigma^{N}_{i=1}(y_i{(p_i)} + (1-y_i)log(1-p_i))}{𝜕𝑤})$$\n",
        "  so\n",
        "$$\n",
        "\\frac{𝜕𝐿(w)}{𝜕𝑤}= \\Sigma^{N}_{i=1}(\\frac{(y_i-p_i)𝜕p_i}{p_i(1-p_i)𝜕𝑤})\n",
        "$$\n",
        " \n",
        "$$\n",
        "  p=σ(w^Tx_i)=\\frac{1}{1+e^{-w^Tx_i}} \\\\\n",
        "  \\frac{𝜕𝐿(w)}{𝜕𝑤}=\\frac{dp}{dw}=\\frac{x_i{e^{-w^Tx_i}}}{({1+e^{-w^Tx_i}})^2} \\\\\n",
        "  \\frac{𝜕𝐿(w)}{𝜕𝑤}=\\frac{dp}{dw}={p(1-p)}x_i \\hspace{1cm} \\hspace{1cm}Eq- 1\n",
        "$$\n",
        "\n",
        " $$ \n",
        "  \\frac{𝜕𝐿(w)}{𝜕𝑤}=>\\Sigma^{N}_{i=1}(y_i(\\frac{p(1-p)x_i}{p})-(1-y_i)(\\frac{p(1-p)x_i}{(1-p)})) $$\n",
        "  Substituting in equation 1 we get\n",
        "$$\\frac{𝜕𝐿(w)}{𝜕𝑤}=>\\Sigma^{N}_{i=1}x_i(y_i-p_i)$$\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "p1eEJiUxlpNr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###x.) It takes 10 minutes to train a SVM algorithm on a dataset with 100K data points.How much time do you think it might take to train the same algorithm on 1 M data points?\n",
        "\n",
        "  If you are referring to standard SVM it has O(N^3) time and O(N^2) space complexity where N is training set size using quadratic programming formulation.\n",
        "$$\n",
        "O(n^3)\n",
        "$$\n",
        "\n",
        "    For 100K = 10^5 points =10 minutes \n",
        "    For 1M = 10^6 points = 10^5*10 = Data is increased by 10 times and time complexity is n^3 so time required increased by 1000 .\n",
        "    So total time is 10*1000 = 10000 minutes  which is quite huge time\n",
        "    "
      ],
      "metadata": {
        "id": "AQcGKlSElr8_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 3\n",
        "\n",
        "**A car insurance company is building a risk assessment prediction system based on the age of the \n",
        "driver and the type of car. \n",
        "Can you help them by building a decision tree using information gain as \n",
        "the split point evaluation measure?**\n"
      ],
      "metadata": {
        "id": "dHn7rhv3SHLg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data = {\n",
        "    'Age of Driver' : [25,20,25,45,20,25],\n",
        "    'Car Type' : ['Sports','Vintage','Sports','SUV','Sports','SUV'],\n",
        "    'Risk' : ['L','H','L','H','H','H'],\n",
        "}\n",
        "df=pd.DataFrame(data)\n",
        "df  # s the sample data:"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "etZduQ8nSajK",
        "outputId": "9d3d9e08-c8b8-4f12-a397-6b003684b2e0"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Age of Driver Car Type Risk\n",
              "0             25   Sports    L\n",
              "1             20  Vintage    H\n",
              "2             25   Sports    L\n",
              "3             45      SUV    H\n",
              "4             20   Sports    H\n",
              "5             25      SUV    H"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7c7ffffd-8f67-4b15-b31d-5b0775a8a083\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age of Driver</th>\n",
              "      <th>Car Type</th>\n",
              "      <th>Risk</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>25</td>\n",
              "      <td>Sports</td>\n",
              "      <td>L</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20</td>\n",
              "      <td>Vintage</td>\n",
              "      <td>H</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>25</td>\n",
              "      <td>Sports</td>\n",
              "      <td>L</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>45</td>\n",
              "      <td>SUV</td>\n",
              "      <td>H</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20</td>\n",
              "      <td>Sports</td>\n",
              "      <td>H</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>25</td>\n",
              "      <td>SUV</td>\n",
              "      <td>H</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7c7ffffd-8f67-4b15-b31d-5b0775a8a083')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7c7ffffd-8f67-4b15-b31d-5b0775a8a083 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7c7ffffd-8f67-4b15-b31d-5b0775a8a083');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# References https://stackoverflow.com/questions/15450192/fastest-way-to-compute-entropy-in-python\n",
        "# Function for calculating entropy\n",
        "def entropy(label1,label2):\n",
        "  tot_le=len(label1)+len(label2)\n",
        "  lb1=len(label1)\n",
        "  lb2=len(label2)\n",
        "  H_pro=lb1/tot_le\n",
        "  L_pro=lb2/tot_le\n",
        "  try:\n",
        "    ent=-(H_pro*math.log2(H_pro)+L_pro*math.log2(L_pro))\n",
        "    return ent\n",
        "  except:\n",
        "    return 0"
      ],
      "metadata": {
        "id": "h8OR5e_gnrmm"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### a. (1 mark) Entropy of the dataset is:"
      ],
      "metadata": {
        "id": "SZ90pTLIy4s9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://medium.com/analytics-vidhya/entropy-calculation-information-gain-decision-tree-learning-771325d16f#:~:text=Entropy%20basically%20tells%20us%20how,homogeneous%20the%20data%20set%20is.%E2%80%9D\n",
        "import math\n",
        "# Entropy of dataset\n",
        "H_df=df[df[\"Risk\"]==\"H\"]\n",
        "L_df=df[df[\"Risk\"]==\"L\"]\n",
        "df_ent=entropy(H_df,L_df)\n",
        "print('a. Entropy of dataset is %.3f' %df_ent)"
      ],
      "metadata": {
        "id": "7IyyfStfTOpG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "f64a2b2d-1620-410d-b1fc-784b20f4a8f5"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a. Entropy of dataset is 0.918\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### b. (1 mark) Calculate the information gain if we split the dataset by the following rule: Age<=22.5\n"
      ],
      "metadata": {
        "id": "YxwiApLRyvdi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def information_gain(sp1,sp2):\n",
        "  tot_len=len(sp1)+len(sp2)\n",
        "  sp1_len=len(sp1)\n",
        "  sp2_len=len(sp2)\n",
        "  H_df=sp1[sp1[\"Risk\"]==\"H\"]\n",
        "  L_df=sp1[sp1[\"Risk\"]==\"L\"]\n",
        "  en1=entropy(H_df,L_df)\n",
        "  H_df=sp2[sp2[\"Risk\"]==\"H\"]\n",
        "  L_df=sp2[sp2[\"Risk\"]==\"L\"]\n",
        "  en2=entropy(H_df,L_df)\n",
        "  frames=[sp1,sp2]\n",
        "  main_df=pd.concat(frames)\n",
        "  main_L=main_df[main_df[\"Risk\"]==\"H\"]\n",
        "  main_H=main_df[main_df[\"Risk\"]==\"L\"]\n",
        "  ans=entropy(main_H,main_L)-((sp1_len)/tot_len)*en1-((sp2_len)/tot_len)*en2\n",
        "  return ans"
      ],
      "metadata": {
        "id": "w_hB3IhfoW_Y"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# information gain for data split on age\n",
        "df_age_less=df[df[\"Age of Driver\"]<=22.5]\n",
        "df_age_more=df[df[\"Age of Driver\"]>22.5]\n",
        "IG_age=information_gain(df_age_less,df_age_more)\n",
        "# print(IG_age)\n",
        "print('b. Information gain for data split on age is %.3f' %IG_age)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "qKtQlLeHnWUp",
        "outputId": "ef99fc40-fe62-4c1a-f9b3-0626cc795495"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b. Information gain for data split on age is 0.252\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# information gain for data split on car ty\n",
        "df_car_sports=df[df[\"Car Type\"]==\"Sports\"]\n",
        "df_not_sports=df[df[\"Car Type\"]!=\"Sports\"]\n",
        "IG_age=information_gain(df_car_sports,df_not_sports)\n",
        "# print(IG_age)\n",
        "print('c.Information gain for data split on car ty is %.3f' %IG_age)"
      ],
      "metadata": {
        "id": "SBM03UMcpiPg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "accb05ec-5951-4a8e-94ea-238b89293206"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "c.Information gain for data split on car ty is 0.459\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# We will take the base case where entropy is 0 or the number of variables we are left with are 0\n",
        "H_df=df_car_sports[df_car_sports[\"Risk\"]==\"H\"]\n",
        "L_df=df_car_sports[df_car_sports[\"Risk\"]==\"L\"]\n",
        "ent_sports=entropy(H_df,L_df)\n",
        "\n",
        "H_df=df_not_sports[df_not_sports[\"Risk\"]==\"H\"]\n",
        "L_df=df_not_sports[df_not_sports[\"Risk\"]==\"L\"]\n",
        "ent_non_sports=entropy(H_df,L_df)\n",
        "\n",
        "# non sports car have zero entropy so we don't have to deal with it"
      ],
      "metadata": {
        "id": "bBHeoLXWqGe8"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### c. (1 mark) Calculate the information gain if we split the dataset by the following rule: Car Type = Sports "
      ],
      "metadata": {
        "id": "rn2cZkicyZka"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('if Car Type = Sports %.3f' %ent_sports)\n",
        "print('if Car Type != Sports %.3f' %ent_non_sports)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Mc37ejQWyC0R",
        "outputId": "f763637e-cdd6-45de-95c9-8c480135a7aa"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "if Car Type = Sports 0.918\n",
            "if Car Type != Sports 0.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "4wOOVlMiyp_F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# splitting sports on Age of Driver basis i.e. age >=22.5 and sports car basis\n",
        "\n",
        "df_age_less=df_car_sports[df_car_sports[\"Age of Driver\"]<22.5]\n",
        "df_age_more=df_car_sports[df_car_sports[\"Age of Driver\"]>=22.5]\n",
        "\n",
        "IG_sports_age=information_gain(df_age_less,df_age_more)\n",
        "print(IG_sports_age)\n",
        "\n",
        "# Here as the IG is very large and the entropy of this dataset is 0 for sports type\n",
        "# splitted on basis of age . We can use the age function in our decision tree.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "HBVCoSvQsUEA",
        "outputId": "94cd0711-9939-44d3-80cb-fc728ec96430"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9182958340544896\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### d. (2 mark) Which of the above two rules should we use for the root-node of the decision tree? Assuming that this is the best choice, can you complete the decision tree?"
      ],
      "metadata": {
        "id": "zNfI7GwEyR28"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Decision Tree\n",
        "\n",
        "def predict(age,car_type):\n",
        "  if car_type!=\"Sports\":\n",
        "    return \"H\"\n",
        "  else:\n",
        "    if age>=22.5:\n",
        "      return \"L\"\n",
        "    else:\n",
        "      return \"H\"\n",
        "\n"
      ],
      "metadata": {
        "id": "zOHK0WGQunI7"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_df=pd.DataFrame(df.copy())\n",
        "predicted=[]\n",
        "for ind in predicted_df.index:\n",
        "  predicted_risk=predict(predicted_df[\"Age of Driver\"][ind],predicted_df[\"Car Type\"][ind])\n",
        "  predicted.append(predicted_risk)\n",
        "predicted_df[\"Predicted Risk\"]=predicted\n",
        "predicted_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "NuJCtrfOvT54",
        "outputId": "6cc2e656-a2bc-46dd-b26f-d02942faae15"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Age of Driver Car Type Risk Predicted Risk\n",
              "0             25   Sports    L              L\n",
              "1             20  Vintage    H              H\n",
              "2             25   Sports    L              L\n",
              "3             45      SUV    H              H\n",
              "4             20   Sports    H              H\n",
              "5             25      SUV    H              H"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b2eca95a-bf75-4baa-872d-7f7ca3e7d76d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age of Driver</th>\n",
              "      <th>Car Type</th>\n",
              "      <th>Risk</th>\n",
              "      <th>Predicted Risk</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>25</td>\n",
              "      <td>Sports</td>\n",
              "      <td>L</td>\n",
              "      <td>L</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20</td>\n",
              "      <td>Vintage</td>\n",
              "      <td>H</td>\n",
              "      <td>H</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>25</td>\n",
              "      <td>Sports</td>\n",
              "      <td>L</td>\n",
              "      <td>L</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>45</td>\n",
              "      <td>SUV</td>\n",
              "      <td>H</td>\n",
              "      <td>H</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20</td>\n",
              "      <td>Sports</td>\n",
              "      <td>H</td>\n",
              "      <td>H</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>25</td>\n",
              "      <td>SUV</td>\n",
              "      <td>H</td>\n",
              "      <td>H</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b2eca95a-bf75-4baa-872d-7f7ca3e7d76d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b2eca95a-bf75-4baa-872d-7f7ca3e7d76d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b2eca95a-bf75-4baa-872d-7f7ca3e7d76d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rocmG4zHtpL8"
      },
      "execution_count": 106,
      "outputs": []
    }
  ]
}